{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame, Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tag_df = pd.read_csv(\"POS.train\", sep = '\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"POS.train\", \"r\") as file:\n",
    "    text =  file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting text from the file\n",
    "\n",
    "word_tag_df_old = DataFrame (text)\n",
    "# extracting the word and the tag in different columns\n",
    "word_tag_df_old = word_tag_df_old[word_tag_df_old.columns[0]].str.rsplit(\"/\", n = 1, expand = True)\n",
    "word_tag_df_old.columns = ['Words', 'Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags before splitting in the original order\n",
    "tags_list = word_tag_df_old['Tags'].to_list()\n",
    "tags_list.insert(0, \"SRT\")\n",
    "for i in range(len(tags_list)):\n",
    "    if tags_list[i] == \".\":\n",
    "        tags_list.insert(i+1, \"SRT\")\n",
    "tags_column_df = DataFrame(tags_list, columns = ['Tags'])\n",
    "# tags_column_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of sentences\n",
    "words_list = word_tag_df_old['Words'].to_list()\n",
    "sentence_list = []\n",
    "sentence = \"\"\n",
    "for word in words_list:\n",
    "    if word != \".\":\n",
    "        sentence += word + \" \"\n",
    "    else: \n",
    "        sentence = sentence[:-1] + \".\"\n",
    "        sentence_list.append(sentence)\n",
    "        sentence = \"\"\n",
    "# sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to seperate tokens for words with multiple tokens\n",
    "# changing the word_tag_df\n",
    "word_tag_df = word_tag_df_old.copy()\n",
    "s = word_tag_df['Tags'].str.split('|').apply(Series, 1).stack()\n",
    "s.index = s.index.droplevel(-1)\n",
    "s.name = 'Tags'\n",
    "del word_tag_df['Tags']\n",
    "word_tag_df = word_tag_df.join(s)\n",
    "# word_tag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a word-tag dictionary\n",
    "word_tag_list = list(word_tag_df.to_records(index=False))        \n",
    "word_tag_dict = {}\n",
    "for x in word_tag_list:\n",
    "#     print(x)\n",
    "    if x[0] not in word_tag_dict.keys():\n",
    "        word_tag_dict[x[0]] ={}\n",
    "        if x[1] not in word_tag_dict[x[0]].keys():\n",
    "            word_tag_dict[x[0]][x[1]] = 1\n",
    "        else:\n",
    "            word_tag_dict[x[0]][x[1]] += 1\n",
    "    else:\n",
    "        if x[1] not in word_tag_dict[x[0]].keys():\n",
    "            word_tag_dict[x[0]][x[1]] = 1\n",
    "        else:\n",
    "            word_tag_dict[x[0]][x[1]] += 1\n",
    "        \n",
    "word_tag_dict['about'][\"IN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinct tag-count dictionary\n",
    "unique_tags_dict = word_tag_df.Tags.value_counts()\n",
    "unique_tags_dict = unique_tags_dict.to_dict()\n",
    "unique_tags_dict[\"SRT\"] = 1\n",
    "# unique_tags_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding probabilites of word-tag\n",
    "word_tag_prob = {}\n",
    "for word, tag_dict in word_tag_dict.items():\n",
    "    for tag in tag_dict.keys():\n",
    "        probablity = float(word_tag_dict[word][tag]/unique_tags_dict[tag])\n",
    "        word_tag_prob[word] = {tag: probablity} \n",
    "# word_tag_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_tag1_tag2_to_dict(tag, prev_tag, tag_dict):\n",
    "    if tag not in tags_pair_dict.keys():\n",
    "        tags_pair_dict[tag] = {prev_tag: [1]}\n",
    "    else:\n",
    "        if tags_list[i-1] not in tags_pair_dict[tag].keys():\n",
    "            tags_pair_dict[tag] = {prev_tag: [1]}\n",
    "        else:\n",
    "            tags_pair_dict[tag][prev_tag][0] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SRT': {'.': [9639]},\n",
       " 'NP': {'NP': [1]},\n",
       " ',': {'NP': [1]},\n",
       " 'CD': {'VBD': [1]},\n",
       " 'NNS': {'JJ': [1]},\n",
       " 'JJ': {'DT': [1]},\n",
       " 'MD': {'NP': [1]},\n",
       " 'VB': {'TO': [5]},\n",
       " 'DT': {'VBG': [1]},\n",
       " 'NN': {'IN': [1]},\n",
       " 'IN': {'NN': [1]},\n",
       " '.': {'NN': [2]},\n",
       " 'VBZ': {'NN': [1]},\n",
       " 'VBG': {'NN': [1]},\n",
       " 'CC': {'NNS': [1]},\n",
       " 'VBD': {'NNS': [1]},\n",
       " 'VBN': {'VBD': [1]},\n",
       " 'RB': {'.': [1]},\n",
       " 'TO': {'NN': [2]},\n",
       " 'PP': {'.': [2]},\n",
       " 'RBR': {'.': [1]},\n",
       " 'WDT': {'IN': [2]},\n",
       " 'VBP': {'NP': [1]},\n",
       " 'PP$': {'VBG': [1]},\n",
       " 'JJS': {'DT': [5]},\n",
       " 'POS': {'NP': [5]},\n",
       " '``': {'VBZ': [1]},\n",
       " 'EX': {'``': [1]},\n",
       " \"''\": {'NN': [1]},\n",
       " 'WP': {'NNS': [1]},\n",
       " 'JJR': {'VBZ': [1]},\n",
       " 'WRB': {',': [1]},\n",
       " 'RP': {'VBG': [1]},\n",
       " '$': {'VBZ': [1]},\n",
       " ':': {'NN': [1]},\n",
       " 'NPS': {'POS': [1]},\n",
       " 'WP$': {':': [1]},\n",
       " '(': {'NNS': [2]},\n",
       " ')': {'CD': [2]},\n",
       " 'PDT': {'RB': [1]},\n",
       " 'RBS': {'PP$': [1]},\n",
       " 'FW': {'FW': [1]},\n",
       " 'UH': {',': [1]},\n",
       " 'SYM': {'NP': [1]},\n",
       " 'LS': {'SRT': [4]},\n",
       " '#': {'IN': [2]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating token-pair dictionary\n",
    "starting_tag = \"SRT\"\n",
    "tags_pair_dict = {}\n",
    "for i in range(len(tags_list)):\n",
    "    if i == 0:\n",
    "        tags_pair_dict[starting_tag] = {tags_list[0]: [1]}\n",
    "    else:\n",
    "        tag2 = tags_list[i]\n",
    "        tag1 = tags_list[i-1]\n",
    "        if ((tag1.find('|') != -1) and (tag2.find('|') != -1)):\n",
    "            for t2_element in tag2.split('|'):\n",
    "                for t1_element in tag1.split('|'):\n",
    "                    adding_tag1_tag2_to_dict(t2_element, t1_element, tags_pair_dict)\n",
    "            \n",
    "        elif tag1.find('|') != -1:\n",
    "            for t1_element in tag1.split('|'):\n",
    "                adding_tag1_tag2_to_dict(tag2, t1_element, tags_pair_dict)\n",
    "                \n",
    "        elif tag2.find('|') != -1:\n",
    "            for t2_element in tag2.split('|'):\n",
    "                adding_tag1_tag2_to_dict(t2_element, tag1, tags_pair_dict)\n",
    "        else:\n",
    "            adding_tag1_tag2_to_dict(tag2, tag1, tags_pair_dict)\n",
    "            \n",
    "tags_pair_dict\n",
    "# tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SRT': {'.': [9639, 0.9637072585482903]},\n",
       " 'NP': {'NP': [1, 4.1967433271781096e-05]},\n",
       " ',': {'NP': [1, 4.1967433271781096e-05]},\n",
       " 'CD': {'VBD': [1, 0.00012851818532322323]},\n",
       " 'NNS': {'JJ': [1, 6.290495061961377e-05]},\n",
       " 'JJ': {'DT': [1, 4.720320981826764e-05]},\n",
       " 'MD': {'NP': [1, 4.1967433271781096e-05]},\n",
       " 'VB': {'TO': [5, 0.0008782715615668365]},\n",
       " 'DT': {'VBG': [1, 0.0002583311805734952]},\n",
       " 'NN': {'IN': [1, 3.951007506914263e-05]},\n",
       " 'IN': {'NN': [1, 2.953598960333166e-05]},\n",
       " '.': {'NN': [2, 5.907197920666332e-05]},\n",
       " 'VBZ': {'NN': [1, 2.953598960333166e-05]},\n",
       " 'VBG': {'NN': [1, 2.953598960333166e-05]},\n",
       " 'CC': {'NNS': [1, 6.464541987200206e-05]},\n",
       " 'VBD': {'NNS': [1, 6.464541987200206e-05]},\n",
       " 'VBN': {'VBD': [1, 0.00012851818532322323]},\n",
       " 'RB': {'.': [1, 9.998000399920016e-05]},\n",
       " 'TO': {'NN': [2, 5.907197920666332e-05]},\n",
       " 'PP': {'.': [2, 0.0001999600079984003]},\n",
       " 'RBR': {'.': [1, 9.998000399920016e-05]},\n",
       " 'WDT': {'IN': [2, 7.902015013828527e-05]},\n",
       " 'VBP': {'NP': [1, 4.1967433271781096e-05]},\n",
       " 'PP$': {'VBG': [1, 0.0002583311805734952]},\n",
       " 'JJS': {'DT': [5, 0.0002360160490913382]},\n",
       " 'POS': {'NP': [5, 0.00020983716635890548]},\n",
       " '``': {'VBZ': [1, 0.00018601190476190475]},\n",
       " 'EX': {'``': [1, 0.0005515719801434088]},\n",
       " \"''\": {'NN': [1, 2.953598960333166e-05]},\n",
       " 'WP': {'NNS': [1, 6.464541987200206e-05]},\n",
       " 'JJR': {'VBZ': [1, 0.00018601190476190475]},\n",
       " 'WRB': {',': [1, 8.192020971573687e-05]},\n",
       " 'RP': {'VBG': [1, 0.0002583311805734952]},\n",
       " '$': {'VBZ': [1, 0.00018601190476190475]},\n",
       " ':': {'NN': [1, 2.953598960333166e-05]},\n",
       " 'NPS': {'POS': [1, 0.0004528985507246377]},\n",
       " 'WP$': {':': [1, 0.000846740050804403]},\n",
       " '(': {'NNS': [2, 0.00012929083974400413]},\n",
       " ')': {'CD': [2, 0.0002275830678197542]},\n",
       " 'PDT': {'RB': [1, 0.00012812299807815503]},\n",
       " 'RBS': {'PP$': [1, 0.0004752851711026616]},\n",
       " 'FW': {'FW': [1, 0.016129032258064516]},\n",
       " 'UH': {',': [1, 8.192020971573687e-05]},\n",
       " 'SYM': {'NP': [1, 4.1967433271781096e-05]},\n",
       " 'LS': {'SRT': [4, 4.0]},\n",
       " '#': {'IN': [2, 7.902015013828527e-05]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag-tag probabilties \n",
    "for tag2 in tags_pair_dict.keys():\n",
    "    for tag1 in tags_pair_dict[tag2].keys():\n",
    "        prob = tags_pair_dict[tag2][tag1][0]/unique_tags_dict[tag1]\n",
    "        tags_pair_dict[tag2][tag1].append(prob)\n",
    "tags_pair_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SRT'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-237ef6de508e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_tags_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_tag_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tag_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtags_pair_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"SRT\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'SRT'"
     ]
    }
   ],
   "source": [
    "# implementing the veterbi algorithm\n",
    "# initialization\n",
    "sent = sentence_list[0].split()\n",
    "new_tags_list = [*unique_tags_dict.keys()]\n",
    "scores = {}\n",
    "back_ptr = {}\n",
    "for tag in new_tags_list:\n",
    "    if tag in word_tag_prob[sent[0]].keys():\n",
    "        scores[(tag, sent[0])] = word_tag_prob[sent[0]][tag] * tags_pair_dict[tag][\"SRT\"]\n",
    "    else:\n",
    "        scores[(tag, sent[0])] = 0\n",
    "# scores\n",
    "# new_tags_list\n",
    "# # sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Max_calculate(score, prev_word, tag2):\n",
    "    index = 0\n",
    "    list_score = []\n",
    "    for index in range(len(new_tags_list)):\n",
    "        if (index, prev_word) in score.keys():\n",
    "            if new_tags_list[index] in tags_pair_dict[tag2].keys():\n",
    "                item = score[(index, prev_word)]*tags_pair_dict[tag2][new_tags_list[index]]\n",
    "                list_score.append(item)\n",
    "            else:\n",
    "                list_score.append(0)\n",
    "    max_score = max(list_score)\n",
    "    max_index = max_score[0]\n",
    "    return max_index, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-f3de992e9d69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_tags_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_tags_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_tag_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m             \u001b[0mmax_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMax_calculate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_tags_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m             \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tag_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_tags_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mback_ptr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_tags_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-5586612eeea1>\u001b[0m in \u001b[0;36mMax_calculate\u001b[1;34m(score, prev_word, tag2)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[0mlist_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mmax_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mmax_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmax_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# iterations in algorithm\n",
    "for i in range(1,len(sent[1:])):\n",
    "    for j in range(len(new_tags_list)):\n",
    "        if new_tags_list[j] in word_tag_prob[sent[i]].keys():      \n",
    "            max_index, max_score = Max_calculate(scores, sent[i-1], new_tags_list[j])\n",
    "            scores[(j, sent[i])] = word_tag_prob[sent[i]][new_tags_list[j]] * max_score\n",
    "            back_ptr[(new_tags_list[j], sent[i])] = max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence identification \n",
    "sequence = {}\n",
    "\n",
    "\n",
    "for w in range(len(sent), 0, -1):\n",
    "    seq{sent[w]} = back_ptr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_max_score(word, probs_score):\n",
    "    max_prob_score = 0\n",
    "    for tag in new_tags_list:\n",
    "        if probs_score> max_prob_score:\n",
    "            max_prob_score = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
